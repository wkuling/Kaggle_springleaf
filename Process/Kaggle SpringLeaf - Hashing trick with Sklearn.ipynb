{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import math\n",
    "from csv import DictReader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "train='C:/Users/m01i795/iPython Notebooks/Kaggle/Input/train.csv'\n",
    "test='C:/Users/m01i795/iPython Notebooks/Kaggle/Input/test.csv'\n",
    "submission = 'C:/Users/m01i795/iPython Notebooks/Kaggle/Output/sgd_subm8.csv'  # path of to be outputted submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "D = 2 ** 24            # number of weights to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hashing function (one hot encoding + hashing)\n",
    "\n",
    "def datahasher(path, D):\n",
    "    ''' GENERATOR: Apply hash-trick to the original csv row\n",
    "                   and for simplicity, we one-hot-encode everything\n",
    "\n",
    "        INPUT:\n",
    "            path: path to training or testing file\n",
    "            D: the max index that we can hash to\n",
    "\n",
    "        YIELDS:\n",
    "            ID: id of the instance, mainly useless\n",
    "            x: a list of hashed and one-hot-encoded 'indices'\n",
    "               we only need the index since all values are either 0 or 1\n",
    "            y: y = 1 if we have a click, else we have y = 0\n",
    "    '''\n",
    "\n",
    "    for t, row in enumerate(DictReader(open(path), delimiter=',')):\n",
    "      \n",
    "        try:\n",
    "            ID=row['ID']\n",
    "            del row['ID']\n",
    "        except:\n",
    "            pass\n",
    "        # process clicks\n",
    "        y = 0.\n",
    "        target='target'\n",
    "        if target in row:\n",
    "            if row[target] == '1':\n",
    "                y = 1.\n",
    "            del row[target]\n",
    "\n",
    "        # extract date\n",
    "\n",
    "        # turn hour really into hour, it was originally YYMMDDHH\n",
    "\n",
    "        # build x\n",
    "        x = []\n",
    "        for key in row:\n",
    "            value = row[key]\n",
    "\n",
    "            # one-hot encode everything with hash trick\n",
    "            index = abs(hash(key + '_' + value)) % D\n",
    "            x.append(index)\n",
    "\n",
    "        yield ID, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-09-20 06:27:51.846000\tencountered: 1000\t\n",
      "2015-09-20 06:27:53.199000\tencountered: 2000\t\n",
      "2015-09-20 06:27:54.673000\tencountered: 3000\t\n",
      "2015-09-20 06:27:56.056000\tencountered: 4000\t\n",
      "2015-09-20 06:27:57.433000\tencountered: 5000\t\n",
      "2015-09-20 06:27:58.793000\tencountered: 6000\t\n",
      "2015-09-20 06:28:00.243000\tencountered: 7000\t\n",
      "2015-09-20 06:28:01.672000\tencountered: 8000\t\n",
      "2015-09-20 06:28:03.078000\tencountered: 9000\t\n",
      "2015-09-20 06:28:04.470000\tencountered: 10000\t\n",
      "2015-09-20 06:28:05.915000\tencountered: 11000\t\n",
      "2015-09-20 06:28:07.282000\tencountered: 12000\t\n",
      "2015-09-20 06:28:09.379000\tencountered: 13000\t\n",
      "2015-09-20 06:28:10.877000\tencountered: 14000\t\n",
      "2015-09-20 06:28:12.214000\tencountered: 15000\t\n",
      "2015-09-20 06:28:13.775000\tencountered: 16000\t\n",
      "2015-09-20 06:28:15.095000\tencountered: 17000\t\n",
      "2015-09-20 06:28:16.720000\tencountered: 18000\t\n",
      "2015-09-20 06:28:19.842000\tencountered: 19000\t\n",
      "2015-09-20 06:28:40.700000\tencountered: 20000\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-08e998ef5676>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatahasher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# datahasher is a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Building the features matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-d031ce76c32c>\u001b[0m in \u001b[0;36mdatahasher\u001b[1;34m(path, D)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# one-hot encode everything with hash trick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create row, col, data arrays (feature and target) by calling datahasher\n",
    "# Note that data are only 1's, as everything is one-hot-encoded...\n",
    "\n",
    "col_features = []\n",
    "row_features = []\n",
    "col_label = []\n",
    "row_label = []\n",
    "\n",
    "count = 0\n",
    "for t, x, y in datahasher(train, D):  # datahasher is a generator\n",
    "    \n",
    "    # Building the features matrix\n",
    "    col_features.extend(x)\n",
    "    to_row = np.full(len(x), count)\n",
    "    row_features.extend(to_row)\n",
    "    \n",
    "    # Building the labels matrix\n",
    "    \n",
    "    col_label.extend([y])\n",
    "    row_label.extend([count])\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "    if count%1000==0:\n",
    "        print('%s\\tencountered: %d\\t' % (datetime.now(), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create COO matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final step of preprocessing: create CSR matrix from COO matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make train and test split using Sklearn train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, run LR, RF, SVM straight out of Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And try some XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
