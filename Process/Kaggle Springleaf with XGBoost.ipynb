{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBeating the benchmark @ Kaggle Springleaf\\nBasis code provided by Abhishek Thakur\\nFurther edits made by Wendell Kuling\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "Beating the benchmark @ Kaggle Springleaf\n",
    "Basis code provided by Abhishek Thakur\n",
    "Further edits made by Wendell Kuling\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing, linear_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('~/ipython/Kaggle_springleaf/Input/train.csv')\n",
    "test = pd.read_csv('~/ipython/Kaggle_springleaf/Input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.target.values\n",
    "train = train.drop(['ID', 'target'], axis=1)\n",
    "test = test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.dropna(axis=1, thresh=2000)\n",
    "test = test.dropna(axis=1, thresh=2000)\n",
    "\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to process some of the day observations\n",
    "def timetodaysago(timeobs):\n",
    "    try:\n",
    "        d0 = datetime.strptime(timeobs[:7], '%d%b%y')\n",
    "        d1 = datetime.strptime('01SEP15', '%d%b%y')\n",
    "        delta = d1 - d0\n",
    "        return delta.days\n",
    "    except:\n",
    "        return timeobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isdate(seriestocheck):\n",
    "    p = re.compile(r'\\w{7}:\\d{2}:\\d{2}:\\d{2}') # regex for our datetime format\n",
    "    for check in seriestocheck:\n",
    "        if p.match(str(check)):\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: VAR_0073 is of type date. Converting.\n",
      "Variable: VAR_0075 is of type date. Converting.\n",
      "Variable: VAR_0156 is of type date. Converting.\n",
      "Variable: VAR_0158 is of type date. Converting.\n",
      "Variable: VAR_0159 is of type date. Converting.\n",
      "Variable: VAR_0166 is of type date. Converting.\n",
      "Variable: VAR_0167 is of type date. Converting.\n",
      "Variable: VAR_0168 is of type date. Converting.\n",
      "Variable: VAR_0169 is of type date. Converting.\n",
      "Variable: VAR_0176 is of type date. Converting.\n",
      "Variable: VAR_0177 is of type date. Converting.\n",
      "Variable: VAR_0178 is of type date. Converting.\n",
      "Variable: VAR_0179 is of type date. Converting.\n",
      "Variable: VAR_0204 is of type date. Converting.\n",
      "Variable: VAR_0217 is of type date. Converting.\n"
     ]
    }
   ],
   "source": [
    "for f in train.columns:\n",
    "    top_values = pd.Series(list(train[f].value_counts().keys()))[:10]\n",
    "    if isdate(top_values):\n",
    "        print \"Variable: \" + f + \" is of type date. Converting.\"\n",
    "        train[f]=train[f].map(timetodaysago)\n",
    "        train[f]=train[f].astype('float64')\n",
    "        test[f]=test[f].map(timetodaysago)\n",
    "        test[f]=test[f].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a row wise count of NA’s \n",
    "\n",
    "train['NumbNAs'] = train.apply(lambda x : x[x==-1].count(), axis = 1)\n",
    "test['NumbNAs'] = train.apply(lambda x : x[x==-1].count(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and row wise count of outliers (those 999…’s). \n",
    "\n",
    "train['Numb99s'] = train.apply(lambda x : x.astype(str).str.contains('99').sum(), axis = 1)\n",
    "test['Numb99s'] = test.apply(lambda x : x.astype(str).str.contains('99').sum(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wendellkuling/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Zip code var 241, 212 (+ID?), 274, 237\n",
    "# Dropping the Zip codes and keeping the values in 274, 237\n",
    "\n",
    "temp = train[['VAR_0274', 'VAR_0237']]\n",
    "temp['target'] = y\n",
    "\n",
    "temp = temp.applymap(lambda x: np.nan if x == -1 else x)\n",
    "\n",
    "tempmean_237 = temp.groupby(['VAR_0237']).mean()\n",
    "searchmean_237 = tempmean_237['target'].to_dict()\n",
    "\n",
    "tempmean_274 = temp.groupby(['VAR_0274']).mean()\n",
    "searchmean_274 = tempmean_274['target'].to_dict()\n",
    "\n",
    "train['at_237'] = train['VAR_0237'].map(lambda x: searchmean_237[x] if (x in searchmean_237) else -1)\n",
    "test['at_237'] = test['VAR_0237'].map(lambda x: searchmean_237[x] if (x in searchmean_237) else -1)\n",
    "\n",
    "train['at_274'] = train['VAR_0274'].map(lambda x: searchmean_274[x] if (x in searchmean_274) else -1)\n",
    "test['at_274'] = test['VAR_0274'].map(lambda x: searchmean_274[x] if (x in searchmean_274) else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['VAR_0241', 'VAR_0212'], axis = 1, inplace = True)\n",
    "test.drop(['VAR_0241', 'VAR_0212'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/darraghdog/springleaf-marketing-response/grouping-numerics-springleaf\n",
    "# We know that VAR_0254, VAR_0255 and VAR_0198 are age features\n",
    "# Creating three columns: one with the best estimate for age, one with avg target score per age-category, \n",
    "# one with avg stdev of target per age-category \n",
    "# dropped the stdev one after experimentation\n",
    "\n",
    "temp = train[['VAR_0254', 'VAR_0255', 'VAR_0198']]\n",
    "temp = temp.applymap(lambda x: np.nan if x == -1 else x)\n",
    "temp['age'] = temp.min(axis='columns')\n",
    "temp['age'] = temp['age'].astype(np.float64)\n",
    "temp.drop(['VAR_0254', 'VAR_0255', 'VAR_0198'], axis = 1, inplace = True)\n",
    "\n",
    "temp['target'] = y\n",
    "\n",
    "tempmean = temp.groupby(['age']).mean()\n",
    "searchmean = tempmean['target'].to_dict()\n",
    "\n",
    "# tempstd = temp.groupby(['age']).std()\n",
    "# searchstd = tempstd['target'].to_dict()\n",
    "\n",
    "temp['at_age'] = temp['age'].map(lambda x: searchmean[x] if (not pd.isnull(x)) else -1)\n",
    "# temp['st_age'] = temp['age'].map(lambda x: searchstd[x] if (not pd.isnull(x)) else -1)\n",
    "\n",
    "train['age'] = temp['age']\n",
    "train['at_age'] = temp['at_age']\n",
    "# train['st_age'] = temp['st_age']\n",
    "\n",
    "\n",
    "temp = test[['VAR_0254', 'VAR_0255', 'VAR_0198']]\n",
    "temp = temp.applymap(lambda x: np.nan if x == -1 else x)\n",
    "temp['age'] = temp.min(axis='columns')\n",
    "temp['age'] = temp['age'].astype(np.float64)\n",
    "temp['at_age'] = temp['age'].map(lambda x: searchmean[x] if (x in searchmean) else -1)\n",
    "# temp['st_age'] = temp['age'].map(lambda x: searchstd[x] if (x in searchstd) else -1)\n",
    "\n",
    "test['age'] = temp['age']\n",
    "test['at_age'] = temp['at_age']\n",
    "# test['st_age'] = temp['st_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(['VAR_0254', 'VAR_0255', 'VAR_0198'], axis = 1, inplace = True)\n",
    "test.drop(['VAR_0254', 'VAR_0255', 'VAR_0198'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR_0001\n",
      "VAR_0005\n",
      "VAR_0008\n",
      "VAR_0009\n",
      "VAR_0010\n",
      "VAR_0011\n",
      "VAR_0012\n",
      "VAR_0043\n",
      "VAR_0044\n",
      "VAR_0196\n",
      "VAR_0200\n",
      "VAR_0202\n",
      "VAR_0216\n",
      "VAR_0222\n",
      "VAR_0226\n",
      "VAR_0229\n",
      "VAR_0230\n",
      "VAR_0232\n",
      "VAR_0236\n",
      "VAR_0237\n",
      "VAR_0239\n",
      "VAR_0274\n",
      "VAR_0283\n",
      "VAR_0305\n",
      "VAR_0325\n",
      "VAR_0342\n",
      "VAR_0352\n",
      "VAR_0353\n",
      "VAR_0354\n",
      "VAR_0404\n",
      "VAR_0466\n",
      "VAR_0467\n",
      "VAR_0493\n",
      "VAR_1934\n"
     ]
    }
   ],
   "source": [
    "for f in train.columns:\n",
    "    if train[f].dtype=='object': \n",
    "        print f\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(train)\n",
    "X_test = np.array(test)\n",
    "clf = xgb.XGBClassifier(n_estimators=5000, nthread=-1, max_depth=17, \n",
    "                        learning_rate=0.01, silent=False, subsample=0.8, colsample_bytree=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bytree=0.7, gamma=0,\n",
       "       learning_rate=0.01, max_delta_step=0, max_depth=17,\n",
       "       min_child_weight=1, missing=None, n_estimators=5000, nthread=-1,\n",
       "       objective='binary:logistic', seed=0, silent=False, subsample=0.8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y, eval_metric = 'auc', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)[:,1]\n",
    "sample = pd.read_csv('~/ipython/Kaggle_springleaf/Input/sample_submission.csv')\n",
    "sample.target = preds\n",
    "sample.to_csv('20151031v3_benchmarkxgb5000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('5000model', 'wb') as handle:\n",
    "    pickle.dump(clf, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To do's:\n",
    "\n",
    "# For binary features > T-SNE clustering on it\n",
    "\n",
    "# (2) from step 1 i got a feature importance list, then split all the ranked feature set into 5 groups by idx mod 5.\n",
    "# Each file would lead a result of ~0.798 in LB, but ensemble these 5 files would lead to 0.8255 in LB.\n",
    "# This is very interesting.\n",
    "\n",
    "\n",
    "# Set evaluation metric to AUC\n",
    "\n",
    "# params = {\"objective\": \"binary:logistic\", \"eta\": 0.015, \"max_depth\": 22, \"min_child_weight\": 3, \n",
    "#      \"silent\": 1, \"subsample\": 0.7, \"colsample_bytree\": 0.7, \"seed\": 231, \"eval_metric\":\"auc\"} num_rounds = 2125\n",
    "\n",
    "# list(objective = \"binary:logistic\", eta = 0.0025, max_depth = 15, \n",
    "# subsample = 0.7, colsample_bytree = 0.5, min_child_weight = 4, eval_metric = \"auc\", alpha = 1)\n",
    "\n",
    "\n",
    "# Build ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ctr_features(data, test, y, ctr_cols, dctr, num):\n",
    "        data[\"target\"] = y\n",
    "        dcols = set(test.columns)\n",
    "        kf = cross_validation.StratifiedKFold(y, n_folds=4, shuffle=True, random_state=11)\n",
    "        tr = np.zeros((data.shape[0], len(ctr_cols)))\n",
    "        for kfold, (itr, icv) in enumerate(kf):\n",
    "            data_tr = data.iloc[itr]\n",
    "            data_te = data.iloc[icv]\n",
    "            for t, col in enumerate(ctr_cols):\n",
    "                if col not in dcols:\n",
    "                    continue\n",
    "                ctr_df = data_tr[[col, \"target\"]].groupby(col).agg([\"count\", \"sum\"])\n",
    "                ctr_dict = ctr_df.apply(lambda x: calc_ctr(x, num), axis=1).to_dict()\n",
    "                tr[icv, t] = data_te[col].apply(lambda x: ctr_dict.get(x, dctr))\n",
    "\n",
    "        te = np.zeros((test.shape[0], len(ctr_cols)))\n",
    "        for t, col in enumerate(ctr_cols):\n",
    "            if col not in dcols:\n",
    "                    continue\n",
    "            ctr_df = data[[col, \"target\"]].groupby(col).agg([\"count\", \"sum\"])\n",
    "            ctr_dict = ctr_df.apply(lambda x: calc_ctr(x, num), axis=1).to_dict()\n",
    "            te[:, t] = test[col].apply(lambda x: ctr_dict.get(x, dctr))\n",
    "        del data[\"target\"]\n",
    "        return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
